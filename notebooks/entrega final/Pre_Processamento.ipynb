{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas e data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixando bibliotecas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from joblib import dump"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020_2021 = pd.read_csv(\"../dados/base_inteli 2020_2021.csv\", sep=\";\" , encoding='utf8')\n",
    "df_1 = pd.DataFrame(data_2020_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022_2023 = pd.read_csv(\"../dados/base_inteli_2022_2023.csv\", sep =\";\", encoding='utf8')\n",
    "df_2 = pd.DataFrame(data_2022_2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação do dolar e da taxa SELIC no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar = pd.read_csv(\"../dados/dolar.csv\", sep =\";\", encoding='utf8')\n",
    "df_dolar = pd.DataFrame(dolar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># convertendo \"data\" do dataset do dólar de string para \"date\", de forma a facilitar o pré-processamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar['data'] = pd.to_datetime(df_dolar['Data e hora da Cotacao']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar = df_dolar.drop(columns=['Data e hora da Cotacao'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionando o intervalo do dataset da Mobly e transformando para realizar o merge entre os dataframes\n",
    "date_threshold = datetime.strptime('2019-05-01', '%Y-%m-%d').date()\n",
    "df_dolar = df_dolar[df_dolar['data'] > date_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando dataset da taxa selic\n",
    "data_selic = pd.read_csv('../dados/selic.csv', sep = \";\", encoding='utf8')\n",
    "df_selic = pd.DataFrame(data_selic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo data do dataset da selic de string para date, de forma a facilitar o pré-processamento\n",
    "df_selic['data'] = df_selic['data'].apply(lambda x: datetime.strptime(x, '%d/%m/%Y').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic['data'] = pd.to_datetime(df_selic['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic['valor'] = df_selic['valor'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic['mes'] = df_selic['data'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic['ano'] = df_selic['data'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media = df_selic.groupby([df_selic['data'].dt.year, df_selic['data'].dt.month])['valor'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media = df_media.rename_axis(['ano','mes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic = pd.merge(df_selic, df_media, how='left', left_on=['mes','ano'], right_on=['mes', 'ano'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic = df_selic.drop(columns=['mes', 'ano', 'valor_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic.rename(columns= {'valor_y': 'selic'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionando o intervalo do dataset da Mobly e transformando para realizar o merge entre os dataframes\n",
    "date_threshold = datetime.strptime('2019-12-30', '%Y-%m-%d')\n",
    "df_selic = df_selic[df_selic['data'] > date_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selic.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenando o data set em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1,df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo o formato da data para realizar o merge\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df_dolar['data'] = pd.to_datetime(df_dolar['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_dolar, how='left', left_on='date', right_on='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['data'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo o formato da data para realizar o merge\n",
    "df_selic['data'] = pd.to_datetime(df_selic['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_selic, how='left', left_on='date', right_on='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nan = df['selic'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nan = df['Cotacao Compra'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preenchendo dados vazios com valores mais próximos\n",
    "df['Cotacao Compra'].fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Cotacao Venda'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Cotacao Compra': 'dolar'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dolar'] = df['dolar'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preenchendo dados vazios com valores mais próximos\n",
    "df['selic'].fillna(method='ffill', inplace=True)\n",
    "df['selic'].fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['data'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selic'] = pd.to_numeric(df['selic'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados = df[df.duplicated(keep='first')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminação de colunas desnecessárias\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Eliminamos a coluna mobly_item pois não interfere no nosso modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['mobly_item'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos a coluna weekday_name pois tratamos a data popsteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['weekday_name'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Eliminamos as colunas relacionadas ao \"bundle\" devido a colinearidade com a coluna \"items_sold\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['flag_bundle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['revenue_bundle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['items_sold_bundle'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Eliminamos a coluna \"supplier_delivery_time\" pois não interfere no nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"supplier_delivery_time\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Eliminamos as colunas relacionadas às medidas do SKU pois não interfere no nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"sku_height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"sku_width\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"sku_weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"sku_length\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Código para verificar o número de células vazias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterando colunas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando coluna \"stock_qty\" para 1 (tem no estoque) ou 0 (não tem no estoque)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['stock_qty'] >= 1, 'stock_qty'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando duas novas colunas no DataFrame: 'is_national', que indica se o produto é de origem Nacional, e 'can_provide_material', que indica se a empresa pode fornecer a matéria-prima para produção com base nas condições fornecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_national'] = df['origin_country'].map({'Nacional': True, 'Importado': False})\n",
    "\n",
    "df['can_provide_material'] = (df['is_national'] & (df['process_costing'] == 'yes'))\n",
    "\n",
    "df = df.drop(columns=['process_costing'])\n",
    "df = df.drop(columns=['origin_country'])\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenchimento das colunas com lagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nas orientações dos parceiros sobre o funcionamento da API de comparação dos preços no Google Shopping, foi percebido que há um preenchimento semanal por SKU, tal que os outros dias da semana permanece o mesmo valor, mas ele não é registrado. Assim, as linhas \"sem registro\" foram preenchidas com lagging a partir do valor mais próximo da data por SKU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['sku', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preenchendo as linhas sem resgitro de winning_price com o preço da semana, preenchendo linhas nulas acima e abaixo\n",
    "df['winning_price'] = df.groupby('sku')['winning_price'].ffill()\n",
    "df['winning_price'] = df.groupby('sku')['winning_price'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo as linhas vazias do \"winning_price\" pois são itens únicos na MObly e não possuem concorrentes \n",
    "df['winning_price'].fillna(df['unit_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#susbtituindo \"Sem |Registro\" por NAN, para aplicar os métodos ffill e bfill\n",
    "df['price_status'].replace('Sem Registro', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preenchendo as linhas sem resgitro de price_status com o preço da semana, preenchendo linhas nulas acima e abaixo\n",
    "df['price_status'] = df.groupby('sku')['price_status'].ffill()\n",
    "df['price_status'] = df.groupby('sku')['price_status'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preenchendo as linhas nulas com \"Uníco Disponpivel\", pois não possuem um status no Google Shopping, por serem itens únicos da Mobly\n",
    "df['price_status'].replace(np.nan, 'Único Disponível', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação das variáveis categóricas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificação dos tipos das variáveis para identificar as categóricas que restaram após os tratamentos de colunas desnecessárias, dados faltantes e inconsistentes para serem codificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ferramenta para transformar variáveis categóricas não numéricas em uma representação numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificação de variáveis categóricas com o LabelEncoder para variáveis que possuem mais de 6 valores únicos e armazenamento do dicionário com o mapeamento para decodificação posterior no notebook do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['sku', 'anchor_category', 'product_department', 'product_category', 'sku_color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_dicts = {}\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    decoding_dicts[column] = dict(zip(range(len(le.classes_)), le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(decoding_dicts, 'decoding_dicts.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificação de variáveis categóricas com o get dummies do pandas (técnica do OneHotEncoder) para variáveis que possuem até 5 valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['shipment_type', 'price_status'], drop_first='True')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento da váriavel date: Separação em outras colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo os componentes da data\n",
    "df['ano'] = df['date'].dt.year\n",
    "df['mes'] = df['date'].dt.month\n",
    "df['dia'] = df['date'].dt.day\n",
    "\n",
    "# 0: Segunda-feira, 1: Terça-feira, etc.\n",
    "df['semana_do_ano'] = df['date'].dt.isocalendar().week\n",
    "df['trimestre'] = df['date'].dt.quarter\n",
    "df['dia_do_ano'] = df['date'].dt.dayofyear\n",
    "df['dia_da_semana'] = df['date'].dt.weekday\n",
    "\n",
    "# Retorna True para sábado e domingo\n",
    "df['fim_de_semana'] = df['date'].dt.weekday >= 5  \n",
    "\n",
    "# Transformação cíclica para o dia do ano\n",
    "df['dia_do_ano_sin'] = np.sin(2 * np.pi * df['dia_do_ano']/365)\n",
    "df['dia_do_ano_cos'] = np.cos(2 * np.pi * df['dia_do_ano']/365)\n",
    "\n",
    "# Transformação cíclica para o dia da semana\n",
    "df['dia_da_semana_sin'] = np.sin(2 * np.pi * df['dia_da_semana']/7)\n",
    "df['dia_da_semana_cos'] = np.cos(2 * np.pi * df['dia_da_semana']/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratando a coluna `date` para tirar segundos, horas ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date).dt.date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora a visualização das últimas 10 linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correção dummies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranformação das variáveis codificadas com dummies \"True\" e \"False\" em 1 e 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_dict = {\n",
    "    True: 1,\n",
    "    False: 0\n",
    "}\n",
    "\n",
    "df = df.replace(dummies_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Eliminando dados anteriores a primeira ocorrência de cada SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def achar_primeira_ocorrencia(df):\n",
    "    condicao = (df.items_sold > 0) | (df.avg_website_visits_last_week > 0)\n",
    "    if condicao.any():\n",
    "        return condicao.idxmax()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "mask = df.groupby(\"sku\").apply(achar_primeira_ocorrencia).reset_index(name=\"achar_primeira_ocorrencia\")\n",
    "df = df.merge(mask, on=\"sku\", how='left')\n",
    "manter_linhas = df.index >= df[\"achar_primeira_ocorrencia\"]\n",
    "\n",
    "#Filtragem do dataframe usando a máscara\n",
    "\n",
    "df_filtrado = pd.DataFrame(df[manter_linhas].drop(columns=['achar_primeira_ocorrencia']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armazenamento df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df\n",
    "\n",
    "%store df_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
