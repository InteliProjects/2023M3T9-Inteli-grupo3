{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puxando Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Pre_Processamento.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, os dados foram divididos em duas versões distintas para testar e comparar os resultados do modelo sob diferentes condições:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remoção de Outliers (``df1``):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do método IQR (Interquartile Range), outliers são identificados e removidos do dataset. Esta medida de dispersão estatística proporciona a amplitude interquartil, facilitando a detecção e filtragem de valores extremos. A aplicação desse método resultou em uma redução aproximada de 9% nos registros originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df['items_sold'].quantile(0.25)\n",
    "q3 = df['items_sold'].quantile(0.75)\n",
    "\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "df1 = df[(df['items_sold'] >= lower_bound) & (df['items_sold'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retirada da Black Friday (``df2``):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta estratégia, semanas relacionadas à Black Friday e início de dezembro são excluídas, dado que tradicionalmente apresentam padrões atípicos de vendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(df[df['semana_do_ano'].isin([46, 47, 48, 49])].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divisão dos datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, foram preparados os conjuntos de dados para treinamento e teste. Em ambos os dataests foram removidas colunas irrelevantes para a modelagem e foram separadas as features (``X``) dos targets (``y``), para cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1.drop(['revenue', 'items_sold', 'date', 'semana_do_ano', 'trimestre', 'dia_do_ano', 'dia_da_semana',\n",
    "       'fim_de_semana'], axis=1)\n",
    "y1 = df1['items_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df2.drop(['revenue', 'items_sold', 'date', 'semana_do_ano', 'trimestre', 'dia_do_ano', 'dia_da_semana',\n",
    "       'fim_de_semana'], axis=1)\n",
    "y2 = df2['items_sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o tratamento inicial dos dados, os conjuntos de features (``X``) e target (``y``) foram preparados para os dois dataframes. Os atributos relacionados a 'revenue', 'items_sold', 'date' e alguns outros foram removidos, pois eles não seriam úteis na etapa de treinamento do modelo.\n",
    "\n",
    "Posteriormente, os dados foram divididos em conjuntos de treino e teste utilizando uma proporção de 70% para treino e 30% para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajuste dos Hiperparâmetros usando Random Search\n",
    ">O método ``Random Search`` é utilizado na otimização de hiperparâmetros. Embora seja possível abranger um vasto espaço de hiperparâmetros, por uma questão de viabilidade de capacidade computacional, a busca foi restrita ao seguinte intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O modelo ideal para a utilização do `Random Search` seria igual a :\n",
    "~~~python\n",
    "random_param_grid = {\n",
    "    'n_estimators': np.arange(50, 1500, 50),\n",
    "    'max_depth': [None] + list(np.arange(5, 31)),\n",
    "    'min_samples_split': np.arange(2, 11),\n",
    "    'min_samples_leaf': np.arange(1, 11),\n",
    "}\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqué feita a busca pelos melhores hiperparâmetros para a versão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search1 = RandomizedSearchCV(\n",
    "    rf_model, random_param_grid, n_iter=5, scoring='neg_mean_squared_error', cv=5, random_state=42\n",
    ")\n",
    "random_search1.fit(X1_train, y1_train)\n",
    "\n",
    "best_random_params1 = random_search1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqué feita a busca pelos melhores hiperparâmetros para a versão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search2 = RandomizedSearchCV(\n",
    "    rf_model, random_param_grid, n_iter=5, scoring='neg_mean_squared_error', cv=5, random_state=42\n",
    ")\n",
    "random_search2.fit(X2_train, y2_train)\n",
    "\n",
    "best_random_params2 = random_search2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">O resultado encontrado pelo `Random Search foram` para o modelo de `RandomForestRegressor`\n",
    "~~~python\n",
    "{\n",
    " 'n_estimators': 100,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_depth': None\n",
    "}\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento sem Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model1 = RandomForestRegressor(n_estimators= 100, min_samples_split= 2, min_samples_leaf= 2, max_depth= None)\n",
    "rf_model1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = rf_model1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae1 = mean_absolute_error(y1_test, y1_pred)\n",
    "print(f\"Erro Médio Absoluto (MAE): {mae1}\")\n",
    "\n",
    "mse1 = mean_squared_error(y1_test, y1_pred)\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse1}\")\n",
    "\n",
    "rmse1 = np.sqrt(mse1)\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse1}\")\n",
    "\n",
    "r21 = r2_score(y1_test, y1_pred)\n",
    "print(f\"Coeficiente de Determinação (R²): {r21}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados obtidos são:\n",
    "\n",
    "- Erro Médio Absoluto (MAE): 0.9307597799264964\n",
    "- Erro Quadrático Médio (MSE): 1.733232060134655\n",
    "- Raiz do Erro Quadrático Médio (RMSE): 1.316522715388783\n",
    "- Coeficiente de Determinação (R²): 0.45169788386178256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Métrica                               | Valor                  |\n",
    "|---------------------------------------|------------------------|\n",
    "| Erro Médio Absoluto (MAE)             | 0.9307597799264964     |\n",
    "| Erro Quadrático Médio (MSE)           | 1.733232060134655      |\n",
    "| Raiz do Erro Quadrático Médio (RMSE)  | 1.316522715388783      |\n",
    "| Coeficiente de Determinação (R²)      | 0.45169788386178256    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento sem Semanas da Black Friday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta fase, o modelo é treinado com os dados onde semanas específicas foram excluídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model2 = RandomForestRegressor(n_estimators= 100, min_samples_split= 2, min_samples_leaf= 2, max_depth= None)\n",
    "rf_model2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = rf_model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae2 = mean_absolute_error(y2_test, y2_pred)\n",
    "print(f\"Erro Médio Absoluto (MAE): {mae2}\")\n",
    "\n",
    "mse2 = mean_squared_error(y2_test, y2_pred)\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse2}\")\n",
    "\n",
    "rmse2 = np.sqrt(mse2)\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse2}\")\n",
    "\n",
    "r22 = r2_score(y2_test, y2_pred)\n",
    "print(f\"Coeficiente de Determinação (R²): {r22}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Métrica                               | Valor                  |\n",
    "|---------------------------------------|------------------------|\n",
    "| Erro Médio Absoluto (MAE)             | 1.4488690788721887     |\n",
    "| Erro Quadrático Médio (MSE)           | 8.389110146760984      |\n",
    "| Raiz do Erro Quadrático Médio (RMSE)  | 2.8963960617914437     |\n",
    "| Coeficiente de Determinação (R²)      | 0.7167009979625879     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussão dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar os resultados, notamos as seguintes observações:\n",
    "\n",
    "**Retirada de Outliers**: A abordagem de remoção de outliers apresentou um erro (tanto MAE quanto RMSE) menor, indicando que o modelo teve um desempenho melhor em termos de precisão da previsão. Entretanto, o coeficiente de determinação (R²) é mais baixo, sugerindo que, apesar das previsões estarem mais próximas dos valores reais, o modelo pode não estar capturando toda a variabilidade dos dados. Uma possível explicação para isso é que ao retirar os outliers, o modelo perdeu parte da informação contida nos dados extremos, o que pode limitar sua capacidade de generalização em certas situações.\n",
    "\n",
    "**Retirada da Black-Friday**: Por outro lado, ao remover as semanas associadas à Black Friday, notamos que o erro é mais elevado, indicando que o modelo tem menos precisão em suas previsões. Entretanto, o coeficiente de determinação (R²) é significativamente maior, sugerindo que o modelo está capturando uma maior proporção da variabilidade dos dados. Isso indica que, apesar de cometer erros maiores em algumas previsões, o modelo é capaz de adaptar-se a uma variedade maior de situações, possivelmente devido ao fato de que ele está lidando com mais dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após uma avaliação dos modelos candidatos (Random Forest, XGBoost e Prophet), concluímos que, comparado aos outros modelos, o Random Forest não se destacou nas métricas de avaliação estabelecidas para nosso projeto. Portanto, optamos por não selecionar o Random Forest como a solução final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
