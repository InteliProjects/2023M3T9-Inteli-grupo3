{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puxando data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodando notebook de pré processamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Pre_Processamento.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando o data frame pré processado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o dataset entre dados de teste e de treino com o método split, que realiza de forma aleatória ao longo do dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['items_sold','revenue'], axis=1) \n",
    "y = df['items_sold']\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos a seleção de features em nosso projeto para identificar as variáveis mais impactantes para a previsão de \"items_sold\", reduzindo assim a complexidade do modelo e o tempo de treinamento. Isso nos permite focar nas features que realmente importam, evitando o ruído e o overfitting, o que contribui para um modelo mais preciso e eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances do Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método Feature Importances usa o algoritmo Random Forest para mostrar quais variáveis têm mais impacto nas previsões. No entanto, uma observação é que esse método nos faz escolher previamente o número de variáveis importantes que queremos focar, o que pode não ser o mais ideal. Nesse caso, decidimos analisar as 5 melhores features com o método. (explicar porquê 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[-5:]\n",
    "X_train_rf_selected = X_train.iloc[:, indices]\n",
    "X_test_rf_selected = X_test.iloc[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf_selected.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select KBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método Select KBest utiliza testes estatísticos para identificar as variáveis que têm maior influência no resultado que queremos prever. Similar ao método de Feature Importances, ele também requer que definamos antecipadamente o número de variáveis importantes a considerar. Aqui também optasmos por analisar as 5 melhores features através deste método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(score_func=f_classif, k=5)\n",
    "X_train_kbest_selected = kbest.fit_transform(X_train, y_train)\n",
    "X_test_kbest_selected = kbest.transform(X_test)\n",
    "selected_cols = X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de correlação em heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de correlação é uma ferramenta essencial na análise de dados que descreve as relações entre as variáveis de um conjunto de dados. No contexto da aplicação do nosso modelo, a matriz de correlação desempenha um papel crucial na compreensão das interações entre as diferentes variáveis que podem influenciar as vendas na Mobly, de modo a trazer insights sobre quais variáveis priorizar ou aquelas que não impactam de forma significativa.\n",
    "\n",
    "Essa matriz nos fornece uma visão geral das associações entre as variáveis, indicando se elas se movem juntas ou em direções opostas. Para construir a matriz de correlação, calculamos coeficientes de correlação, como o coeficiente de correlação de Pearson, entre pares de variáveis. Esses coeficientes variam de -1 a 1, onde -1 representa uma correlação negativa perfeita, 1 representa uma correlação positiva perfeita e 0 indica ausência de correlação.\n",
    "\n",
    "Ao examinar a matriz de correlação, podemos identificar variáveis que têm forte influência nas vendas da Mobly e, assim, priorizar nossos esforços na modelagem. Essa análise também pode nos alertar para possíveis multicolinearidades, onde duas variáveis estão altamente correlacionadas entre si, o que pode afetar a estabilidade do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "\n",
    "labels = ['sku', 'unit_price', 'anchor_category', 'product_department',\n",
    "       'product_category', 'sku_color', 'winning_price',\n",
    "       'avg_website_visits_last_week', 'stock_qty', 'items_sold_b\"undle',\n",
    "       'dolar', 'shipment_type_próprio', 'origin_country_Nacional',\n",
    "       'price_status_Ganhando', 'price_status_Perdendo',\n",
    "       'price_status_Sem Registro', 'price_status_Único Disponível',\n",
    "       'process_costing_yes', 'mes', 'dia', 'semana_do_ano', 'trimestre',\n",
    "       'dia_do_ano', 'dia_da_semana', 'fim_de_semana', 'dia_do_ano_sin',\n",
    "       'dia_do_ano_cos', 'dia_da_semana_sin', 'dia_da_semana_cos', 'ano_2021',\n",
    "       'ano_2022', 'ano_2023']\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em conclusão, foi possível perceber diversasa análises com grande contribuição para o projeto. Por exemplo, houve uma altissima correlação entre winning_price e process_costing yes, o que era esperado, uma vez que produtos beneficiados tem um preço menor, e portanto, maior vendas. Foi identificado também uma inesperada correlação entre o dólar, a média de visita do site e a quantidade de estoque, estando com uma correlação maior que o esperado, indicando a relevâncias desses atributos no modelo. Portanto, a matriz de correlação foi uma ferramenta essencial na etapa de preparação de dados e análise exploratória, ajudando-nos a entender as relações entre as variáveis e a escolher as mais relevantes para a previsão de vendas na Mobly, contribuindo para um modelo mais preciso e eficaz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
